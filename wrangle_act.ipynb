{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "\n",
    "import requests\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "import json\n",
    "from pynlp import Stanford\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the tweet image predictions tsv file via requests library\n",
    "\n",
    "url = 'https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'\n",
    "response = requests.get(url)\n",
    "with open(url.split('/')[-1], mode = 'wb') as file:\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read `image predictions tsv file`\n",
    "\n",
    "predict_dog = pd.read_csv('image-predictions.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read `twitter archive enhanced.csv` file to get tweet ids for API\n",
    "\n",
    "twitter_df = pd.read_csv('twitter-archive-enhanced.csv')\n",
    "# extract tweet ids only for use in API\n",
    "\n",
    "tweet_id = twitter_df['tweet_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T RUN THIS CELL!\n",
    "# Authenticate Tweepy PI\n",
    "\n",
    "consumer_key = '8UqkSZEX9dQ8eeVjTulXO3hrs'\n",
    "consumer_secret = '6sswY9LumipSfGRrMC4K0O5eRdB0FEHGmzJPJsXN8ivAQhursG'\n",
    "access_token = '1009804608540200960-Z4DNl7IqVa4CNS0us678UUu5WGyqJU'\n",
    "access_secret = 'pHgvsF4YSNcePNCBXqTfgmjeWVHQmAzfLZaOyiaOO5sFT'\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit = True, wait_on_rate_limit_notify = True,\n",
    "                 parser=tweepy.parsers.JSONParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 348\n",
      "Rate limit reached. Sleeping for: 242\n"
     ]
    }
   ],
   "source": [
    "# DON'T RUN THIS CELL!\n",
    "# Get tweet JSON data using tweet ID via Tweepy \n",
    "\n",
    "tweet_json = []\n",
    "error_list = []\n",
    "for i in tweet_id:\n",
    "    try:\n",
    "        tweet = api.get_status(i, tweet_mode = 'extended')\n",
    "        tweet_json.append(tweet)\n",
    "    except:\n",
    "        error_list.append(i)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T RUN THIS CELL!\n",
    "# Write JSON data to tweet_json.txt file with each tweet's JSON data on its own line\n",
    "\n",
    "with open('tweet_json.txt', 'w') as outfile:\n",
    "    json.dump(tweet_json, outfile, indent = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read tweet_json.txt file into a pandas data frame \n",
    "\n",
    "pd_json = pd.read_json('tweet_json.txt', orient = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract only needed columns (tweet_id, favorite_count, retweet_count)\n",
    "# Save it to tweet_json\n",
    "\n",
    "tweet_json = pd_json[['id','favorite_count','retweet_count']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality\n",
    "##### `twitter_df` table\n",
    "- some tweets was deleted or invalid (2356 instead of 2345)\n",
    "- missing data in `in_reply_to_status_id` column\n",
    "- missing data in `in_reply_to_user_id` column\n",
    "- missing data in `retweeted_status_id` column\n",
    "- missing data in `retweeted_status_user_id` column\n",
    "- missing data in `retweeted_status_timestamp` column\n",
    "- `source` and `expanded_urls` columns are not relevant to our analysis\n",
    "- `name` content is not always a name, sometimes it's an adjective or articles\n",
    "\n",
    "\n",
    "\n",
    "##### `predict_dog` table\n",
    "- missing records because some tweets are without images (2075 instead of 2356) or invalid or deleted\n",
    "- not all images are for dogs! some images are for other animals\n",
    "\n",
    "##### `tweet_json` table\n",
    "- `id` column name is not consistent with other tables same column names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tidiness\n",
    "##### `twitter_df` table\n",
    "- `doggo`, `floofer`, `pupper` and `puppo` should be values for a `stage` column not seperate columns\n",
    "- `time stamp` column should be two separate columns for `date` and `time`\n",
    "\n",
    "##### `tweet_json` table\n",
    "- the whole table should be merged with `twitter_archive` table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the datasets to work with and clean\n",
    "\n",
    "twitter_df_clean = twitter_df.copy()\n",
    "predict_dog_clean = predict_dog.copy()\n",
    "tweet_json_clean = tweet_json.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean\n",
    "### Define\n",
    "### Quality \n",
    "##### `twitter_df` table\n",
    "- remove all records with ids in `error_list`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all records with ids in `error_list`\n",
    "\n",
    "for record in error_list:\n",
    "    twitter_df_clean.drop(twitter_df_clean[twitter_df_clean.tweet_id == record].index, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    2344\n",
       "Name: tweet_id, dtype: int64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if any record with id from error_list still exists!\n",
    "\n",
    "twitter_df_clean['tweet_id'].isin(error_list).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define\n",
    "### Quality\n",
    "##### `twitter_df` table\n",
    "- drop `in_reply_to_status_id`, `in_reply_to_user_id`, `retweeted_status_id`,  \n",
    "  `retweeted_status_user_id`, `retweeted_status_timestamp`, `source` and `expanded_urls` columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop 'in_reply_to_status_id', 'in_reply_to_user_id', 'retweeted_status_id',\n",
    "# 'retweeted_status_user_id' and 'retweeted_status_timestamp' columns from `twitter_archive_clean` table\n",
    "\n",
    "twitter_df_clean.drop(columns = ['in_reply_to_status_id', 'in_reply_to_user_id',\n",
    "                                 'retweeted_status_id', 'retweeted_status_user_id',\n",
    "                                 'retweeted_status_timestamp', \n",
    "                                 'source', 'expanded_urls'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>text</th>\n",
       "      <th>rating_numerator</th>\n",
       "      <th>rating_denominator</th>\n",
       "      <th>name</th>\n",
       "      <th>doggo</th>\n",
       "      <th>floofer</th>\n",
       "      <th>pupper</th>\n",
       "      <th>puppo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2351</th>\n",
       "      <td>666049248165822465</td>\n",
       "      <td>2015-11-16 00:24:50 +0000</td>\n",
       "      <td>Here we have a 1949 1st generation vulpix. Enj...</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2352</th>\n",
       "      <td>666044226329800704</td>\n",
       "      <td>2015-11-16 00:04:52 +0000</td>\n",
       "      <td>This is a purebred Piers Morgan. Loves to Netf...</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>a</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2353</th>\n",
       "      <td>666033412701032449</td>\n",
       "      <td>2015-11-15 23:21:54 +0000</td>\n",
       "      <td>Here is a very happy pup. Big fan of well-main...</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>a</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2354</th>\n",
       "      <td>666029285002620928</td>\n",
       "      <td>2015-11-15 23:05:30 +0000</td>\n",
       "      <td>This is a western brown Mitsubishi terrier. Up...</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>a</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2355</th>\n",
       "      <td>666020888022790149</td>\n",
       "      <td>2015-11-15 22:32:08 +0000</td>\n",
       "      <td>Here we have a Japanese Irish Setter. Lost eye...</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                tweet_id                  timestamp  \\\n",
       "2351  666049248165822465  2015-11-16 00:24:50 +0000   \n",
       "2352  666044226329800704  2015-11-16 00:04:52 +0000   \n",
       "2353  666033412701032449  2015-11-15 23:21:54 +0000   \n",
       "2354  666029285002620928  2015-11-15 23:05:30 +0000   \n",
       "2355  666020888022790149  2015-11-15 22:32:08 +0000   \n",
       "\n",
       "                                                   text  rating_numerator  \\\n",
       "2351  Here we have a 1949 1st generation vulpix. Enj...                 5   \n",
       "2352  This is a purebred Piers Morgan. Loves to Netf...                 6   \n",
       "2353  Here is a very happy pup. Big fan of well-main...                 9   \n",
       "2354  This is a western brown Mitsubishi terrier. Up...                 7   \n",
       "2355  Here we have a Japanese Irish Setter. Lost eye...                 8   \n",
       "\n",
       "      rating_denominator  name doggo floofer pupper puppo  \n",
       "2351                  10  None  None    None   None  None  \n",
       "2352                  10     a  None    None   None  None  \n",
       "2353                  10     a  None    None   None  None  \n",
       "2354                  10     a  None    None   None  None  \n",
       "2355                  10  None  None    None   None  None  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at the data frame to see the columns is removed\n",
    "twitter_df_clean.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define\n",
    "### Quality\n",
    "##### `twitter_df` table\n",
    "-  edit `name` contents to ensure they are real dog names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first make sure all records are for dogs by matching the `predict_dog_clean` non-dog ids with ones in `twitter_df_clean`\n",
    "\n",
    "non_dogs = predict_dog_clean[(predict_dog_clean.p1_dog == False)\n",
    "                                         | (predict_dog_clean.p2_dog == False)\n",
    "                                         | (predict_dog_clean.p3_dog == False)].tweet_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all non-dog records in twitter_df_clean\n",
    "\n",
    "for record in non_dogs:\n",
    "    twitter_df_clean.drop(twitter_df_clean[twitter_df_clean.tweet_id == record].index, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1515\n",
       "Name: tweet_id, dtype: int64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if any record with id from non_dogs still exists!\n",
    "\n",
    "twitter_df_clean['tweet_id'].isin(non_dogs).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define\n",
    "### Quality \n",
    "##### `predict_dog` table\n",
    "- remove all non dog records by keeping only the records where `p1_dog`, `p2_dog`, `p3_dog` are all `True`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all non-dog records by keeping only the records where `p1_dog`, `p2_dog`, `p3_dog` are all `True`\n",
    "\n",
    "predict_dog_clean.drop(predict_dog_clean[(predict_dog_clean.p1_dog == False)\n",
    "                                         | (predict_dog_clean.p2_dog == False)\n",
    "                                         | (predict_dog_clean.p3_dog == False)].index, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1243\n",
       "Name: tweet_id, dtype: int64"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if any non-dog record exists!\n",
    "\n",
    "predict_dog_clean['tweet_id'].isin(non_dogs).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define\n",
    "### Quality \n",
    "##### `tweet_json` table\n",
    "- rename `id` column to `tweet_id` for consistency with other tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
