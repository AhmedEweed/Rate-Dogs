{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "\n",
    "import requests\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the tweet image predictions tsv file via requests library\n",
    "\n",
    "url = 'https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'\n",
    "response = requests.get(url)\n",
    "with open(url.split('/')[-1], mode = 'wb') as file:\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read `image predictions tsv file`\n",
    "\n",
    "image_predictions = pd.read_csv('image-predictions.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read `twitter archive enhanced.csv` file to get tweet ids for API\n",
    "\n",
    "twitter_archive = pd.read_csv('twitter-archive-enhanced.csv')\n",
    "# extract tweet ids only for use in API\n",
    "\n",
    "tweet_id = twitter_archive['tweet_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T RUN THIS CELL!\n",
    "# Authenticate Tweepy PI\n",
    "\n",
    "consumer_key = ''\n",
    "consumer_secret = ''\n",
    "access_token = ''\n",
    "access_secret = ''\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit = True, wait_on_rate_limit_notify = True,\n",
    "                 parser=tweepy.parsers.JSONParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 170\n",
      "Rate limit reached. Sleeping for: 27\n"
     ]
    }
   ],
   "source": [
    "# DON'T RUN THIS CELL!\n",
    "# Get tweet JSON data using tweet ID via Tweepy \n",
    "\n",
    "tweet_json = []\n",
    "error_list = []\n",
    "for i in tweet_id:\n",
    "    try:\n",
    "        tweet = api.get_status(i, tweet_mode = 'extended')\n",
    "        tweet_json.append(tweet)\n",
    "    except:\n",
    "        error_list.append(i)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T RUN THIS CELL!\n",
    "# Write JSON data to tweet_json.txt file with each tweet's JSON data on its own line\n",
    "\n",
    "with open('tweet_json.txt', 'w') as outfile:\n",
    "    json.dump(tweet_json, outfile, indent = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read tweet_json.txt file into a pandas data frame \n",
    "\n",
    "tweet_json = pd.read_json('tweet_json.txt', orient = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract only needed columns (tweet_id, favorite_count, retweet_count)\n",
    "# Save it to tweet_df_trim \n",
    "\n",
    "tweet_json_trim = tweet_json[['id','favorite_count','retweet_count']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality\n",
    "##### `twitter_archive` table\n",
    "- missing ids in 'in_reply_to_status_id' column\n",
    "- missing ids in 'in_reply_to_user_id' column\n",
    "- missing ids in 'retweeted_status_id' column\n",
    "- missing ids in 'retweeted_status_user_id' column\n",
    "- missing ids in 'retweeted_status_timestamp' column\n",
    "- not all `name` content is a name! sometimes it's an adjective or articles\n",
    "\n",
    "##### `image_predictions` table\n",
    "- not all images are for dogs! some images are for other animals\n",
    "- missing records because some tweets are without images (270 missing)\n",
    "\n",
    "##### `tweet_json_trim` table\n",
    "- missing tweet ids for invalid or deleted ones (11 missing)\n",
    "- `id` should be named `tweeter_id` to be consistent with other tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tidiness\n",
    "##### `twitter_archive` table\n",
    "- `doggo`, `floofer`, `pupper` and `puppo` should be values for a `stage` column not seperate columns\n",
    "- `time stamp` column should be two columns for `date` and `time`\n",
    "- `in_reply_to_status_id`, `in_reply_to_user_id`, `retweeted_status_id`, `retweeted_status_user_id`\n",
    "  and `retweeted_status_timestamp` columns should be dropped since they are almost full of nulls\n",
    "  and don't have our desired information\n",
    "\n",
    "##### `tweet_json_trim` table\n",
    "- the whole table should be merged with `twitter_archive` table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
