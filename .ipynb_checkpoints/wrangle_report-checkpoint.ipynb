{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This report describes my efforts spent on gathering, assessing and cleaning datasets about `WeRateDogs` twitter\n",
    "hashtag tweet contents.  \n",
    "`WeRateDogs` is a twitter account that rates dog images tweeted on twitter which started in November 2015..  \n",
    "The report will be divided into Three portions for each phase of work:\n",
    "\n",
    "- Gather: this describes the efforts of collecting needed files and store them in aproperiate file extensions  \n",
    "\n",
    "\n",
    "- Asses: this describes the visual and programmatic display of data so that I can see any faults or errors\n",
    "\n",
    "  and this phase is divided into two aspects:  \n",
    "  \n",
    "  - Quality: mention the Quality issues found in each dataset\n",
    "  - Tidiness: mention the Tidiness issues found in each dataset  \n",
    "  \n",
    "  \n",
    "- Clean: this describes the cleaning efforts and how I solved data-related problems  \n",
    "\n",
    "  and this phase is also divided into two aspects:\n",
    "  \n",
    "  - Quality: mention how the Quality issues found in each dataset were solved and cleared\n",
    "  - Tidiness: mention how the Tidiness issues found in each dataset were solved and cleared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gather\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, I worked on collecting the data required for the project as follows:  \n",
    "\n",
    "- `twitter_archive_enhanced.csv` file that was given to me at hand for direct download from Udacity's page  \n",
    "   and all I did was downloading it and then reading it to my project workspace.  \n",
    "   \n",
    "\n",
    "- `image_predictions.tsv` file that I was given only its server url,\n",
    "   and I had to fetch it using the `requests` library and store it in a local file.  \n",
    "   \n",
    "\n",
    "- `tweet_json.txt` file that I had to collect via Twitter API, then write it line by line  \n",
    "  to a text file so I can read it later into a dataframe.  \n",
    "  I used `tweet_id` column data from `twitter_archive_enchanced` to collect the right data from Twitter  \n",
    "  but I faced the fact that some ids are invalid or no longer exist via the API.  \n",
    "  So, I collected the 'faulty' ids in a list called `error_list` for later use  \n",
    "  to remove any data related to them in other tables to keep all the data consistent and concise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After gathering needed data, time for assessing!  I read the data files in three dataframes  \n",
    "as `twitter_df`, `predict_dog` and `tweet_json` respectively  \n",
    "Both Quality and Tidiness issues is addressed here:  \n",
    "\n",
    "- Quality: as for Quality issues, I found a bunch of them in each table as follows:  \n",
    "\n",
    "    - `twitter_df` table  \n",
    "    \n",
    "        - some tweets was deleted or invalid (2356 instead of 2345) found in `error_list`\n",
    "        - `tweet_id` column type is integer althogh it should be string\n",
    "        - `timestamp` column type is object meaning string but it should be datetime\n",
    "        - `in_reply_to_status_id`, `in_reply_to_user_id`, `retweeted_status_id`, `retweeted_status_user_id`\n",
    "            and `retweeted_status_timestamp` columns have values rather than `NaN`  \n",
    "            that is not the criteria of the analysis we need only original tweets no retweet or replies\n",
    "        - `in_reply_to_status_id`, `in_reply_to_user_id`, `retweeted_status_id`, `retweeted_status_user_id`\n",
    "           and `retweeted_status_timestamp` don't add useful information to our dataset no more\n",
    "\n",
    "    - `predict_dog` table  \n",
    "    \n",
    "        - `tweet_id` column type is integer although it should be string \n",
    "        - invalid records because some tweets are deleted from the archive\n",
    "        - not all images are for dogs! some images are for other animals\n",
    "\n",
    "    - `tweet_json` table  \n",
    "    \n",
    "        - `id` column type is integer although it should be string\n",
    "        - `id` column name is not consistent with other tables same column names\n",
    "\n",
    "\n",
    "- Tidiness: as for Tidiness issues, I found a couple of issues in each table as follows:\n",
    "\n",
    "    - `twitter_df` table\n",
    "        - `time stamp` column should be two separate columns for `date` and `time`\n",
    "\n",
    "    - `predict_dog` table\n",
    "        - the whole table should be merged with `twitter_df` table \n",
    "\n",
    "    - `tweet_json` table\n",
    "        - the whole table should be merged with `twitter_df` table "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After assessing and figuring out the problems tha is in our data, time for Cleaning!  \n",
    "Cleaning will also be discussed on Quality and Tidiness basis  \n",
    "Before I did any Cleaning, I made a copy of each table to do my cleaning steps on them  \n",
    "that's safer and more elegent!\n",
    "\n",
    "- Quality: as for Quality issues, I worked hard to solve them as:  \n",
    "\n",
    "    - `twitter_df_clean` table:\n",
    "        - remove all records with ids in `error_list` from the API work before and that will make sure  \n",
    "        our data is consistent along all tables  \n",
    "        \n",
    "        - drop all full-of-NAN columns for they are not relevant to our analysis  \n",
    "        and also will make no sense with all that missing values  \n",
    "        \n",
    "        - drop all non relevant columns as they will not be helpful for us \n",
    "        \n",
    "        - I tried to extract real dog names from `text` via text analysis techniques  \n",
    "        but no success! I think a poor algorithm was used in the first place when gathering that piece of data  \n",
    "        I worked to remove all one character names like `a` and `an` but again that was not as desired!  \n",
    "               \n",
    "    - `predict_dog_clean` table:\n",
    "        - remove all records with ids in `error_list` from the API work before  \n",
    "        to make sure all data pieces is consistent  \n",
    "        - I did some cool work in this part!  \n",
    "        I matched only records where at least `p1_dog` or `p2_dog` or `p3_dog` columns was True  \n",
    "        and the results were rewarding!  \n",
    "        - drop not relevant columns since they are of no help for us in our analysis  \n",
    "        \n",
    "    - `tweet_json_clean` table:\n",
    "        - rename `id` column to `tweet_id` to be consistent with other tables' same content columns  \n",
    "        \n",
    "        \n",
    "- Tidiness: as for Tidiness issues, I woked hard to solve them as:\n",
    "    - `twitter_df_clean` table:\n",
    "        - This one was the hardest for me! I searched for `melt` and `pivot` functions  \n",
    "        but they were not I wished for. So, I did it with a simple loop to find the column value  \n",
    "        and assign it to the new `stage` column it the right position  \n",
    "        - split based on date and time and store the result in a separate column for each type of information  \n",
    "    \n",
    "    - `predict_dog_clean` table:\n",
    "        - merge `predict_dog_clean` `with twitter_df_clean` on matching `tweet_id`\n",
    "    \n",
    "    - `tweet_json_clean` table:\n",
    "        - merge `tweet_json_clean` with `twitter_df_clean` on matching `tweet_id`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
